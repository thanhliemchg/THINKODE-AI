import streamlit as st
import google.generativeai as genai
from prompts import SYSTEM_PROMPT
from guard import is_blocked, blocked_reply
import csv, os
from datetime import datetime
from PyPDF2 import PdfReader

# =========================
# CONFIG GEMINI (FREE)
# =========================
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel("gemini-1.5-flash")

# =========================
# LOG SETUP
# =========================
LOG_FILE = "data/logs.csv"
os.makedirs("data", exist_ok=True)

if not os.path.exists(LOG_FILE):
    with open(LOG_FILE, "w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow(["time", "mode", "question"])

# =========================
# UI
# =========================
st.set_page_config(page_title="THINKODE AI", page_icon="üß†")
st.title("üß† THINKODE AI")
st.caption("Think before Code ‚Äì Tr·ª£ gi·∫£ng AI hu·∫•n luy·ªán t∆∞ duy l·∫≠p tr√¨nh")

mode = st.selectbox(
    "üéØ Ch·ªçn ch·∫ø ƒë·ªô h·ªó tr·ª£:",
    [
        "Ph√¢n t√≠ch ƒë·ªÅ b√†i",
        "G·ª£i √Ω h∆∞·ªõng ti·∫øp c·∫≠n",
        "Ki·ªÉm tra t∆∞ duy",
        "ƒê√°nh gi√° ƒë·ªô ph·ª©c t·∫°p",
        "Ph√¢n t√≠ch ƒë·ªÅ t·ª´ file PDF"
    ]
)

# =========================
# FILE UPLOAD
# =========================
uploaded_file = st.file_uploader(
    "üìé ƒê√≠nh k√®m ƒë·ªÅ b√†i (PDF, kh√¥ng b·∫Øt bu·ªôc)",
    type=["pdf"]
)

def read_pdf(file):
    reader = PdfReader(file)
    text = ""
    for page in reader.pages:
        if page.extract_text():
            text += page.extract_text() + "\n"
    return text

pdf_text = ""
if uploaded_file is not None:
    pdf_text = read_pdf(uploaded_file)

# =========================
# SESSION STATE
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]

for msg in st.session_state.messages[1:]:
    st.chat_message(msg["role"]).write(msg["content"])

user_input = st.chat_input("üí¨ Nh·∫≠p c√¢u h·ªèi l·∫≠p tr√¨nh c·ªßa em...")

# =========================
# GEMINI ASK FUNCTION
# =========================
def ask_ai(messages):
    """
    Gemini kh√¥ng d√πng format role nh∆∞ OpenAI,
    n√™n gh√©p to√†n b·ªô h·ªôi tho·∫°i th√†nh 1 prompt l·ªõn.
    """
    prompt = ""
    for m in messages:
        if m["role"] == "system":
            prompt += f"[H·ªÜ TH·ªêNG]\n{m['content']}\n\n"
        elif m["role"] == "user":
            prompt += f"[H·ªåC SINH]\n{m['content']}\n\n"
        elif m["role"] == "assistant":
            prompt += f"[TR·ª¢ GI·∫¢NG]\n{m['content']}\n\n"

    response = model.generate_content(prompt)
    return response.text

# =========================
# MAIN CHAT LOGIC
# =========================
if user_input:
    st.chat_message("user").write(user_input)

    with open(LOG_FILE, "a", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow([datetime.now(), mode, user_input])

    if is_blocked(user_input):
        reply = blocked_reply()
    else:
        content = f"CH·∫æ ƒê·ªò: {mode}\n\n"

        if pdf_text:
            content += (
                "N·ªòI DUNG ƒê·ªÄ B√ÄI T·ª™ FILE PDF (tr√≠ch y·∫øu):\n"
                + pdf_text[:4000]
                + "\n\n"
            )

        content += f"C√ÇU H·ªéI C·ª¶A H·ªåC SINH:\n{user_input}"

        st.session_state.messages.append({
            "role": "user",
            "content": content
        })

        reply = ask_ai(st.session_state.messages)

    st.session_state.messages.append({
        "role": "assistant",
        "content": reply
    })
    st.chat_message("assistant").write(reply)
